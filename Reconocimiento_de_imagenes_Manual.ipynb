{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/2fw+5hEjdDqSjaHIVLR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nelo0ut/Reconocimiento-de-imagenes/blob/main/Reconocimiento_de_imagenes_Manual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui realizamos la conexion a nuestro Drive para poder hacer uso de nuestra data que hemos compartido previamente en el Manual"
      ],
      "metadata": {
        "id": "0E2z0mYokrXm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5JzfRWqczXd",
        "outputId": "47d7be14-708e-45ea-eb88-9e7c17cad35d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos las libreas que iremos a usar"
      ],
      "metadata": {
        "id": "pfwXqYpok6JN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.datasets import load_files\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "import keras.utils as image\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import cv2"
      ],
      "metadata": {
        "id": "51T2nrXvc06q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establecemos algunas variables para realizar el cargado de nuestro modelo"
      ],
      "metadata": {
        "id": "4yOerkhhlM_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "longitud, altura = 150, 150\n",
        "tamano_filtro1 = (3, 3)\n",
        "tamano_filtro2 = (2, 2)\n",
        "tamano_pool = (2, 2)\n",
        "clases = 10\n",
        "lr = 0.0001"
      ],
      "metadata": {
        "id": "9p2QzwLIddkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora si realizamos el cargado de nuestro modelo que servirá para el cargado de las imagenes y su reconocimiento"
      ],
      "metadata": {
        "id": "1el6DO85lXBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = Sequential()\n",
        "cnn.add(Convolution2D(16, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "cnn.add(Convolution2D(32, tamano_filtro2, padding =\"same\"))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "cnn.add(Convolution2D(64, tamano_filtro2, padding =\"same\"))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "cnn.add(Convolution2D(128, tamano_filtro2, padding =\"same\"))\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(256, activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(clases, activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eU3SIio4dinQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y finalmente tenemos nuestro aplicativo para el reconocimiento de imagenes, no olvidar de importar los modelos y pesos ademas de la carpeta con imagenes que quiera reconocer en su drive para su ejecución"
      ],
      "metadata": {
        "id": "Ttv6kchDlfAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "longitud, altura = 150, 150\n",
        "modelo = '/content/drive/MyDrive/modelo3/modelo.h5'\n",
        "pesos_modelo = '/content/drive/MyDrive/modelo3/pesos.h5'\n",
        "\n",
        "cnn = load_model(modelo)\n",
        "cnn.load_weights(pesos_modelo)\n",
        "\n",
        "def predict(file):\n",
        "  x = load_img(file, target_size=(longitud, altura))\n",
        "  x = img_to_array(x)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  array = cnn.predict(x)\n",
        "  result = array[0]\n",
        "  answer = np.argmax(result)\n",
        "  if answer == 0:\n",
        "    print(\"pred: Audifonos\")\n",
        "  elif answer == 1:\n",
        "    print(\"pred: Billetera\")\n",
        "  elif answer == 2:\n",
        "    print(\"pred: Botella\")\n",
        "  elif answer == 3:\n",
        "    print(\"pred: Cama\")\n",
        "  elif answer == 4:\n",
        "    print(\"pred: Cuaderno\")\n",
        "  elif answer == 5:\n",
        "    print(\"pred: Laptop\")\n",
        "  elif answer == 6:\n",
        "    print(\"pred: Mochila\")\n",
        "  elif answer == 7:\n",
        "    print(\"pred: Monitor\")\n",
        "  elif answer == 8:\n",
        "    print(\"pred: Mouse\")\n",
        "  elif answer == 9:\n",
        "    print(\"pred: Teclado\")\n",
        "\n",
        "  return answer\n",
        "\n",
        "predict('/content/drive/MyDrive/Test/cuaderno.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GQ06e9-dynI",
        "outputId": "3231e209-ed4b-4bc7-c014-33dade838231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 123ms/step\n",
            "pred: Cuaderno\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}